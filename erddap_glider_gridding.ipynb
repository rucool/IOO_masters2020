{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# load, process, and grid ERDDAP \n",
    "\n",
    "An attempt make the real-time glider data easier to work with. Once its in this format, it should be easy to grab sections using the `.sel(date = slice() )` methods of xarray. You should also have an easier time calcuating stuff, and plotting agaist time, lat or lon\n",
    "\n",
    "This is a little fast and loose, so caveat emptor for science!\n",
    "\n",
    "## to do:\n",
    "We could(should) just convert this into a function to be run by another notebook. \n",
    "input to that function would probably be the glider dataset ID, and the variables you want"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import pandas as pd\n",
    "from erddapy import ERDDAP\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import cartopy.crs as ccrs\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from scipy.signal import find_peaks\n",
    "\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# this creates a link to the RUCOOL server:\n",
    "e = ERDDAP(\n",
    "    server=\"http://slocum-data.marine.rutgers.edu/erddap\",\n",
    "    protocol=\"tabledap\",\n",
    "    response=\"nc\",\n",
    ")\n",
    "\n",
    "# get the science data:\n",
    "e.dataset_id = 'ru29-20200908T1623-profile-sci-rt'\n",
    "\n",
    "# this connects to the data and load into an pandas dataframe\n",
    "ds = e.to_pandas()\n",
    "# remove the spaces from the column names\n",
    "ds.columns = ds.columns.str.split(' ').str[0]\n",
    "\n",
    "# get the time to be a datetime object\n",
    "ds['time'] = pd.to_datetime(ds['time'])\n",
    "\n",
    "# put the times in order\n",
    "ds = ds.sort_values(by=['time'])\n",
    "\n",
    "print(ds.info())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# fill nans in depth for the profile breakup\n",
    "interpd = ds.depth.interpolate()\n",
    "\n",
    "plt.plot(ds.depth.values, '.')\n",
    "plt.plot(interpd.values, '.')\n",
    "plt.xlim([0, 1e4])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# find the top and bottom of each profile\n",
    "apogee, prop = find_peaks(interpd.values,  threshold=None, \n",
    "                          distance=None, prominence=50)\n",
    "\n",
    "perogee, prop = find_peaks(-1*interpd.values,  threshold=None, \n",
    "                           distance=None, prominence=50)\n",
    "\n",
    "# stack the index of the turning points into one vector\n",
    "turns = np.sort(np.append(apogee, perogee ))\n",
    "turns.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# check your work\n",
    "plt.plot(ds.time, ds.depth)\n",
    "plt.plot(ds.time[apogee], ds.depth[apogee], 'o')\n",
    "plt.plot(ds.time[perogee], ds.depth[perogee], 'o')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# look in more detail\n",
    "plt.plot( ds.depth)\n",
    "plt.plot( ds.depth[apogee], 'o')\n",
    "plt.plot( ds.depth[perogee], 'o')\n",
    "plt.plot( ds.depth[turns])\n",
    "plt.xlim([0, 1e4 ])\n",
    "\n",
    "# plt.xlim([4.2e5, 4.5e5 ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# GRID!\n",
    "\n",
    "build a useful dataset for analysis. We will grid some stuff in time and depth, then grid some 1-d stuff to make coordinates and put it all together into an xarray dataset\n",
    "\n",
    "## start with '2D' gridding\n",
    "\n",
    "here we are going to bin (grid) stuff that has 2 dimentions: time and depth\n",
    "\n",
    "for example: temp, salin, ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# this is your depth grid, you can set:\n",
    "zgrd = np.arange(0,1000,5)\n",
    "\n",
    "# list of variables to grid in 2d:\n",
    "# you choose from the columns of the science data\n",
    "# this should be the input to a function you create\n",
    "dataz = ['potential_temperature', 'salinity', \n",
    "         'cdom', 'chlorophyll_a', 'beta_700nm']\n",
    "\n",
    "\n",
    "# this is a dict to hold our gridded stuff\n",
    "# until we make a dataset later\n",
    "d2 = {}\n",
    "\n",
    "# loop on the variables you want to bin\n",
    "for varz in dataz:    \n",
    "    values = ds[varz] # grab this data\n",
    "    \n",
    "    #this thing below bins the data\n",
    "    ret = stats.binned_statistic_2d(ds.index.values, ds.depth, \n",
    "                                    values, statistic='mean', bins=[ turns, zgrd ])\n",
    "    d2[varz] = ret.statistic.T\n",
    "    \n",
    "d2.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# make a quick plot of the results\n",
    "plt.pcolormesh(d2['potential_temperature'] )\n",
    "# plt.xlim([0, 40])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## next: bin some '1D' stuff\n",
    "these are things that dont have a depth dimention:\n",
    "like, time, lat, lon, u, v, ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# things to bin in the x direction\n",
    "# these also prob need defn in the function call\n",
    "oneDvars = ['latitude','longitude', 'time', 'u', 'v']\n",
    "\n",
    "# NB: u, v only have one value per dive sequence, so only half the number profiles!\n",
    "# actually, its weirder than that... not sure there are more than half...\n",
    "\n",
    "# dict to hold our 1d bins\n",
    "d1 = {}\n",
    "\n",
    "# loop on 1d stuff:\n",
    "for thing in oneDvars:    \n",
    "    # time variable needs to be treated a little differently\n",
    "    if thing == 'time':\n",
    "        bin_means, bin_edges, binnumber = stats.binned_statistic(ds.index.values,\n",
    "                    ds[thing].astype(int), statistic = 'mean', bins=turns)\n",
    "        bin_means = pd.to_datetime(bin_means)\n",
    "        \n",
    "    # if we aren't binning time, things are normal\n",
    "    else:\n",
    "    \n",
    "        bin_means, bin_edges, binnumber = stats.binned_statistic(ds.index.values,\n",
    "                    ds[thing].values, statistic = np.nanmean, bins=turns)\n",
    "    d1[thing] = bin_means\n",
    "    \n",
    "d1.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# check out work\n",
    "plt.plot(d1['time'], d1['u'],'.')\n",
    "\n",
    "plt.figure()\n",
    "plt.quiver(d1['longitude'], d1['latitude'], d1['u'], d1['v'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# how many non-nan u and v's?\n",
    "# this is confusing\n",
    "# also, this is not a main issue right now, but needs attention\n",
    "print( np.count_nonzero( ~np.isnan(d1['v']) ) , ' non-nan velocites')\n",
    "\n",
    "# this plot shows us that the velocity values are reported near the surface \n",
    "plt.plot(interpd.values, ds.u.values, '.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# put it all together\n",
    "\n",
    "Now we can add these things together into an xarray dataset that will be easier to work with.\n",
    "\n",
    "We've created 2D data, and some dims / coords to go with the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# need the depth grid centers\n",
    "zgrd_ctr = zgrd[:-1] + np.diff(zgrd).mean()/2\n",
    "\n",
    "# create the dataset\n",
    "ds_gridded = xr.Dataset( coords = {\n",
    "                           'date': d1['time'].values,\n",
    "                           'depth': zgrd_ctr ,\n",
    "                           'lat': ('date', d1['latitude']),\n",
    "                           'lon': ('date', d1['longitude'])\n",
    "                          },\n",
    "               data_vars = {'u': ('date', d1['u']), \n",
    "                           'v': ('date', d1['v'])})\n",
    "\n",
    "# add the other data in a loop\n",
    "# for varz in dataz:\n",
    "for varz in d2.keys():\n",
    "    ds_gridded[varz] = ( ('depth', 'date'),d2[varz] )\n",
    "\n",
    "    \n",
    "# thie line below will save the netcdf if you want to work with it in another notebook    \n",
    "# ds_gridded.to_netcdf('./glider_gridded.nc')\n",
    "\n",
    "ds_gridded\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# make a simple plot\n",
    "ds_gridded.potential_temperature.plot( yincrease=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# make a section plot\n",
    "this should be easier now, but this belongs in another notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# can we select a time?\n",
    "section = ds_gridded.sel( date = \n",
    "                         slice('2020-10-18T13:04:29.446530048','2020-10-20T07:42:28.419889920' ) )\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(ds_gridded.lon, ds_gridded.lat,'.')\n",
    "plt.plot(section.lon, section.lat,'.')\n",
    "\n",
    "plt.figure()\n",
    "section.potential_temperature.plot(yincrease=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "rise": {
   "scroll": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
